---
title: "Rongkui_Chap14.5_Hw"
author: "Rongkui Han"
date: "6/21/2020"
output: 
  html_document: 
    keep_md: yes
---

Q14M4
```{r}
library(rethinking)
```

Gaussian process model
```{r}
data(Kline2) # load the ordinary data, now with coordinates
d <- Kline2
data(islandsDistMatrix)
d$society <- 1:10 # index observations

dat_list <- list(
  T = d$total_tools,
  P = d$population,
  society = d$society,
  Dmat=islandsDistMatrix )
  
m14.7 <- ulam(
  alist(
  T ~ dpois(lambda),
  lambda <- (a*P^b/g)*exp(k[society]),
  vector[10]:k ~ multi_normal( 0 , SIGMA ),
  matrix[10,10]:SIGMA <- cov_GPL2( Dmat , etasq , rhosq , 0.01 ),
  c(a,b,g) ~ dexp( 1 ),
  etasq ~ dexp( 2 ),
  rhosq ~ dexp( 0.5 )
  ), data=dat_list , chains=4 , cores=4 , iter=2000, log_lik = TRUE )


```

NON-centered Gaussian process model
```{r}
m14.7nc <- ulam( 
  alist(
  T ~ dpois(lambda),
  lambda <- (a*P^b/g)*exp(k[society]),
# non-centered Gaussian Process prior
  transpars> vector[10]: k <<- L_SIGMA * z,
  vector[10]: z ~ normal( 0 , 1 ),
  transpars> matrix[10,10]: L_SIGMA <<- cholesky_decompose( SIGMA ),
  transpars> matrix[10,10]: SIGMA <- cov_GPL2( Dmat , etasq , rhosq , 0.01 ),
  c(a,b,g) ~ dexp( 1 ),
  etasq ~ dexp( 2 ),
  rhosq ~ dexp( 0.5 )
  ), data=dat_list , chains=4 , cores=4 , iter=2000, log_lik = TRUE)
```



Poisson GLM moodel
```{r}
d$P <- scale( log(d$population) ) 
d$contact_id <- ifelse( d$contact=="high" , 2 , 1 )

dat2 <- list(
  T = d$total_tools ,
  P = d$P ,
  cid = d$contact_id )

m11.10 <- ulam(
  alist(
  T ~ dpois( lambda ),
  log(lambda) <- a[cid] + b[cid]*P,
  a[cid] ~ dnorm( 3 , 0.5 ),
  b[cid] ~ dnorm( 0 , 0.2 )
  ), data=dat2 , chains=4, iter=2000, log_lik=TRUE )

```

```{r}
compare(m14.7, m14.7nc, m11.10)
```

> The gaussian process model is much better than the poisson GLM model. It has fewer effective parameters, a lower WAIC and a smaller standard error. The centered and non-centered model are essentially the same. 

## Plotting posteriors

14.7
```{r 14.40}
post <- extract.samples(m14.7) 
# plot the posterior median covariance function
plot( NULL , xlab="distance (thousand km)" , ylab="covariance" ,
xlim=c(0,10) , ylim=c(0,2) )
# compute posterior mean covariance
x_seq <- seq( from=0 , to=10 , length.out=100 )
pmcov <- sapply( x_seq , function(x) post$etasq*exp(-post$rhosq*x^2) )
pmcov_mu <- apply( pmcov , 2 , mean )
lines( x_seq , pmcov_mu , lwd=2 )
# plot 60 functions sampled from posterior
for ( i in 1:50 )
curve( post$etasq[i]*exp(-post$rhosq[i]*x^2) , add=TRUE ,
col=col.alpha("black",0.3) )
```

```{r 14.41}
# compute posterior median covariance among societies
K <- matrix(0,nrow=10,ncol=10)
for ( i in 1:10 )
for ( j in 1:10 )
K[i,j] <- median(post$etasq) *
exp( -median(post$rhosq) * islandsDistMatrix[i,j]^2 )
diag(K) <- median(post$etasq) + 0.01
```

```{r 14.42}
# convert to correlation matrix
Rho <- round( cov2cor(K) , 2 )
# add row/col names for convenience
colnames(Rho) <- c("Ml","Ti","SC","Ya","Fi","Tr","Ch","Mn","To","Ha")
rownames(Rho) <- colnames(Rho)
Rho
```

```{r 14.43}
# scale point size to logpop 
psize <- d$logpop / max(d$logpop)
psize <- exp(psize*1.5)-2
# plot raw data and labels
plot( d$lon2 , d$lat , xlab="longitude" , ylab="latitude" ,
col=rangi2 , cex=psize , pch=16 , xlim=c(-50,30) )
labels <- as.character(d$culture)
text( d$lon2 , d$lat , labels=labels , cex=0.7 , pos=c(2,4,3,3,4,1,3,2,4,2) )
# overlay lines shaded by Rho
for( i in 1:10 )
for ( j in 1:10 )
if ( i < j )
lines( c( d$lon2[i],d$lon2[j] ) , c( d$lat[i],d$lat[j] ) ,
lwd=2 , col=col.alpha("black",Rho[i,j]^2) )
```

```{r 14.44}
# compute posterior median relationship, ignoring distance
logpop.seq <- seq( from=6 , to=14 , length.out=30 )
lambda <- sapply( logpop.seq , function(lp) post$a*exp(lp)^post$b/post$g )
lambda.median <- apply( lambda , 2 , median )
lambda.PI80 <- apply( lambda , 2 , PI , prob=0.8 )
# plot raw data and labels
plot( d$logpop , d$total_tools , col=rangi2 , cex=psize , pch=16 ,
xlab="log population" , ylab="total tools" )
text( d$logpop , d$total_tools , labels=labels , cex=0.7 ,
pos=c(4,3,4,2,2,1,4,4,4,2) )
# display posterior predictions
lines( logpop.seq , lambda.median , lty=2 )
lines( logpop.seq , lambda.PI80[1,] , lty=2 )
lines( logpop.seq , lambda.PI80[2,] , lty=2 )
# overlay correlations
for( i in 1:10 )
for ( j in 1:10 )
if ( i < j )
lines( c( d$logpop[i],d$logpop[j] ) ,
c( d$total_tools[i],d$total_tools[j] ) ,
lwd=2 , col=col.alpha("black",Rho[i,j]^2) )
```

