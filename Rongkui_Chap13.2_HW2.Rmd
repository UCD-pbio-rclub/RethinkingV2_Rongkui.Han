---
title: "Rongkui_Chap13.2_HW"
author: "Rongkui Han"
date: "1/24/2020"
output: html_document
---

###12M4.   

Fit the following cross-classified multilevel model to the chimpanzees data:    

$$
L_i \sim Binomial(1, p_i)\\
logit(p_i) = \alpha_{actor[i]} + \alpha_{block[i]} + (\beta_P + \beta_{PC}Ci)Pi\\
\alpha_{actor} \sim Normal(\alpha, \sigma_{actor})\\
\alpha_{block} \sim Normal(\gamma, \sigma_{block})\\
\alpha, \gamma, \beta_p, \beta_{PC} \sim Normal(0, 10)\\
\sigma_{actor}, \sigma_{block} \sim HalfCauchy(0, 1)
$$

Each of the parameters in those comma-separated lists gets the same independent prior. Compare
the posterior distribution to that produced by the similar cross-classified model from the chapter.
Also compare the number of effective samples. Can you explain the differences?    

```{r}
library(rethinking)
data(chimpanzees)
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
dat_list <- list(
  pulled_left = d$pulled_left,
  actor = d$actor,
  block_id = d$block,
  treatment = as.integer(d$treatment) )
```

Original model:     
```{r}
m11.4 <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a[actor] + g[block_id] + b[treatment] ,
    a[actor] ~ dnorm( 0 , 1.5 ),
    g[block_id] ~ dnorm( 0 , 1.5 ),
    b[treatment] ~ dnorm( 0 , 0.5 )) ,
  data=dat_list , chains=4 )
```

```{r}
precis( m11.4 , depth=2 )
```

```{r}
plot(m11.4, depth = 2)
```


New model:  
```{r}
m13.4 <- ulam(
  alist(
    pulled_left ~ dbinom( 1 , p ) ,
    logit(p) <- a_bar + z[actor]*sigma_a + g_bar + y[block_id]*sigma_g + b[treatment],
    b[treatment] ~ dnorm(0,1),
    c(a_bar, g_bar) ~ dnorm(0,1),
    z[actor] ~ dnorm(0,1),
    y[block_id] ~ dnorm(0,1),
    c(sigma_a, sigma_g) ~ dexp(1)
  ), 
  data=dat_list , chains=4 , cores=4 , log_lik=TRUE )
```

```{r}
precis( m13.4 , depth=2 )
```

```{r}
plot(m13.4, depth = 2)
```

Compare n_eff:   
```{r}
library(ggplot2)
n_eff1 = as.data.frame(precis(m11.4, depth=2 )[['n_eff']])
names(n_eff1) = 'n_eff'

n_eff2 = as.data.frame(precis(m13.4, depth=2 )[['n_eff']])
names(n_eff2) = 'n_eff'

ggplot() +
  geom_histogram(data = n_eff1, aes(x = n_eff, fill = 'salmon'), bins = 20, alpha = 0.5) +
  geom_histogram(data = n_eff2, aes(x = n_eff, fill = 'turquoise'), bins = 20, alpha = 0.5) +
  scale_fill_manual(name = 'the fill', guide = 'legend', , 
         values =c('salmon'='salmon','turquoise'='turquoise'), labels = c("m11.4","m13.4"))
```



### 12H3.      

The Trolley data are also clustered by `story`, which indicates a unique narrative for each
vignette. Define and fit a cross-classified varying intercepts model with both `id` and `story`. Use the
same ordinary terms as in the previous problem. Compare this model to the previous models. What
do you infer about the impact of different stories on responses?     

```{r}
data(Trolley)
d_T<- Trolley

dat_T <- list(
  R = d_T$response,
  A = d_T$action,
  I = d_T$intention,
  C = d_T$contact,
  id = as.numeric(d_T$id),
  story = as.numeric(d_T$tory)
)
```

```{r, eval = FALSE}
m12h2.2 <- ulam( alist(
  R ~ dordlogit( phi , cutpoints ),
  phi <- a[id] + bA*A + bC*C + BI*I ,
  BI <- bI + bIA*A + bIC*C , 
  a[id] ~ dnorm(0, sigma),  
  c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
  cutpoints ~ dnorm( 0 , 1.5 ),
  sigma ~ dexp(1)) ,
  data=dat_T, chains=2, log_lik = TRUE)
save(m12h2.2, file = "/Users/rongkui/Desktop/StatisticalRethinking/m12h2.2.RData")
```

```{r}
m12h2.3 <- ulam( alist(
  R ~ dordlogit( phi , cutpoints ),
  phi <- a[id] + g[story] + bA*A + bC*C + BI*I ,
  BI <- bI + bIA*A + bIC*C , 
  a[id] ~ dnorm(0, sigma_a),  
  g[story] ~ dnorm(0, sigma_g), 
  c(bA,bI,bC,bIA,bIC) ~ dnorm( 0 , 0.5 ),
  cutpoints ~ dnorm( 0 , 1.5 ),
  c(sigma_a, sigma_g) ~ dexp(1)) ,
  data=dat_T, chains=2, log_lik = TRUE)
save(m12h2.3, file = "/Users/rongkui/Desktop/StatisticalRethinking/m12h2.3.RData")
```

```{r}
load("/Users/rongkui/Desktop/StatisticalRethinking/m12h2.2.RData")
load("/Users/rongkui/Desktop/StatisticalRethinking/m12h2.3.RData")
compare(m12h2.2, m12h2.3)
```

